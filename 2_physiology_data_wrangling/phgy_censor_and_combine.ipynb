{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592bbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.stats import zscore\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c9cd7",
   "metadata": {},
   "source": [
    "Purpose: wrangle the physiology metrics that were output by mousephgymetrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00453891",
   "metadata": {},
   "source": [
    "Python environment: clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f2e83",
   "metadata": {},
   "source": [
    "Note: run this script from the folder in which it is located so the relative paths work correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8da9d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e93607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the physiological metrics that we computed from the resp and pleth traces (e.g. HR, RR, PVI, HRV, RV, RRV)\n",
    "final_data_folder='../phgy_derivatives/physiology_analysis_outputs'\n",
    "resp_csvs = sorted(glob.glob(final_data_folder + '/*resp*window.csv'))\n",
    "pulseox_csvs = sorted(glob.glob(final_data_folder + '/*pleth*window.csv'))\n",
    "\n",
    "#for spo2, we didn't need to compute any downstream metrics, the original (cleaned) data is already the output that we need\n",
    "spo2_csvs = sorted(glob.glob('../../3_preprocessed_data/phgy_data_oldNaming/*spo2*'))\n",
    "\n",
    "#also load the motion measure (FD) computed by rabies\n",
    "rabies_FD_csv_path = '/data/chamal/projects/mila/2021_fMRI_dev/part2_phgy_fmri_project/4_derivatives/rabies_runs/local_data_final_runs/rabies_out_preprocess-v050/motion_datasink/FD_csv/*/*/'\n",
    "\n",
    "#load the timeseries of fmri censoring, so that we can also censor the phgy timeseries to get the same number of timepoints for fmri and phgy\n",
    "rabies_censoring_csv_path = '/data/chamal/projects/mila/2021_fMRI_dev/part2_phgy_fmri_project/4_derivatives/rabies_runs/local_data_final_runs/rabies_out_cc-v050_05smoothed_lowpass/confound_correction_datasink/frame_censoring_mask/*/' \n",
    "\n",
    "#finally, load the dataset specs\n",
    "dataset_info_df = pd.read_csv(\"../../2_raw_data/dataset_specs.csv\").set_index(\"epi_filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c146f",
   "metadata": {},
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d90ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_array_of_phgy_with_dict(resp_files, pulseox_files, spo2_files, rabies_censoring_csv_path,\n",
    "                                    rabies_FD_csv_path,range_files_to_extract,\n",
    "                                    output_dict_bool, original_num_timepoints, censoring_duration_dict, dataset_info_df):\n",
    "    '''This function combines the resp and pulseox csvs for a given subject/session, drops unimportant variables\n",
    "    and censors according to the RABIES temporal mask. Will also do additional physiology censoring (remove \n",
    "    corrupted timepoints) and drop NaN values. All while properly keeping track of the shape. '''\n",
    "    phgy_dict_allvar = {}\n",
    "    phgy_dict_selectvar = {}\n",
    "    phgy_dict_selectvar_precensor = {}\n",
    "    phgy_dict_selectvar_zscored = {}\n",
    "    phgy_nan_censoring_dict = {}\n",
    "    fmri_phgy_nan_censoring_dict = {}\n",
    "    phgy_shape_postCensor_dict = {}\n",
    "    session_info_dict = {}\n",
    "    \n",
    "    \n",
    "    #iterate over all csvs and extract an array from each, store outputs in a dict\n",
    "    for i in range(range_files_to_extract[0], range_files_to_extract[1]):\n",
    "        num_files_to_extract = range_files_to_extract[1] - range_files_to_extract[0]\n",
    "        filename = os.path.basename(os.path.abspath(resp_files[i]))\n",
    "        ses = filename[2:3]\n",
    "        sub = filename[4:7]\n",
    "        sub_ses_ID = 'sub-PHG' + str(sub) + '_ses-' + str(ses)\n",
    "        \n",
    "        #find corresponding rabies csv\n",
    "        rabies_censoring_csv = sorted(glob.glob(str(rabies_censoring_csv_path) + '/' + (sub_ses_ID) + '*.csv'))\n",
    "        rabies_FD_csv = sorted(glob.glob(str(rabies_FD_csv_path) + '/' + (sub_ses_ID) + '*rest*.csv')) \n",
    "        \n",
    "        #load as df\n",
    "        resp_df = pd.read_csv(resp_files[i]).drop(columns = ['Unnamed: 0', 'Window start time',\n",
    "                                                            'Window end time'], axis = 1)\n",
    "        pulseox_df = pd.read_csv(pulseox_files[i]).drop(columns = ['Unnamed: 0', 'Window start time',\n",
    "                                                            'Window end time'], axis = 1)\n",
    "        spo2_df = pd.read_csv(spo2_files[i], names = ['SpO2 (%)'])\n",
    "        rabies_censoring_df = pd.read_csv(os.path.abspath(rabies_censoring_csv[0]))\n",
    "        rabies_FD_df = pd.read_csv(os.path.abspath(rabies_FD_csv[0]))\n",
    "\n",
    "        #concatenate resp, pulseox, spo2 and FD together\n",
    "        phgy_df_allvar = pd.concat([resp_df.add_suffix('-resp'), pulseox_df.add_suffix('-pleth'), spo2_df], axis = 1)\n",
    "        \n",
    "        #extract relevant information about the scan to keep, repeat it for each timepoint\n",
    "        session_info_once = pd.DataFrame(dataset_info_df.loc[sub_ses_ID][0:13]).transpose()\n",
    "        session_info_repeated = session_info_once.loc[session_info_once.index.repeat(original_num_timepoints)].reset_index()\n",
    "        \n",
    "        #extract the iso info, repeat it appropriately for each iso condition at each timepoint\n",
    "        iso_info = pd.DataFrame([dataset_info_df.loc[sub_ses_ID,:]['iso_percent_low']]*480 + [dataset_info_df.loc[sub_ses_ID,:]['iso_percent_mid']]*480 + [dataset_info_df.loc[sub_ses_ID,:]['iso_percent_high']]*480, \n",
    "                                columns = ['isoflurane_percent'])   \n",
    "        \n",
    "        #also keep track of the time (how far into the scan we are)\n",
    "        time1 = pd.DataFrame([*range(0,1440)], columns = ['Time after scan start'])\n",
    "        time2 = pd.DataFrame([*range(0,480)]*3, columns = ['Time after isoflurane change'])\n",
    "        \n",
    "        #concatenate the session_info and iso_info and FD\n",
    "        full_session_info = pd.concat([time1, time2, session_info_repeated, iso_info, rabies_FD_df.add_suffix(' FD')],\n",
    "                                      axis = 1)\n",
    "        \n",
    "        \n",
    "        #drop redundant variables that are highly correlated (see next section for the justification)\n",
    "        #also drop std in window, entropy and pulse width because they're harder to interpret and less grounded in lit\n",
    "        phgy_df_selectvar = phgy_df_allvar.drop(columns = ['Period-overall window mean-resp',\n",
    "                                                           'Resp rate-overall window-resp',\n",
    "                                                           'Instantanous RRV period rmssd-window mean-resp',\n",
    "                                                           'RRV-overall period window rmssd-resp',\n",
    "                                                           'RRV-overall period window std-resp',\n",
    "                                                           'Period-overall window mean-pleth',\n",
    "                                                           'HR-overall window-pleth',\n",
    "                                                           'Instantanous HRV period rmssd-window mean-pleth',\n",
    "                                                           'HRV-overall period window rmssd-pleth',\n",
    "                                                           'HRV-overall period window std-pleth',\n",
    "                                                           'Instantaneous resp rate - window std-resp',\n",
    "                                                          'Instantaneous HR - window std-pleth',\n",
    "                                                          'Instantaneous entropy-window mean-resp',\n",
    "                                                          'Instantaneous entropy-window mean-pleth',\n",
    "                                                          'Width at quarter height-overall window mean-pleth',\n",
    "                                                          'width at half height-overall window mean-pleth',\n",
    "                                                          'Width at base-overall window mean-pleth'], axis = 1)\n",
    "        #rename the existing column names to simpler ones\n",
    "        phgy_df_selectvar = phgy_df_selectvar.rename(columns={\"Instantaneous resp rate-window mean-resp\": \"RR\",\n",
    "                                                              \"Instantaneous RV - window mean-resp\": \"RV\", \n",
    "                                                              \"Instantaneous RRV period std-window mean-resp\": \"RRV\",\n",
    "                                                              \"Instantaneous HR-window mean-pleth\": \"HR\",\n",
    "                                                              \"Instantaneous HRV period std-window mean-pleth\": \"HRV\",\n",
    "                                                              \"Instantaneous PVI-window mean-pleth\": \"PVI\", \n",
    "                                                             \"SpO2 (%)\": \"SpO2\"})\n",
    "        #change order of RV and RRV (to better parallel the order of pulse ox metrics)\n",
    "        phgy_df_selectvar.insert(1, 'RRV', phgy_df_selectvar.pop('RRV'))\n",
    "        phgy_df_selectvar = phgy_df_selectvar.astype(float)\n",
    "        \n",
    "        ################################ CENSORING ##################################\n",
    "        #drop rows in phgy data that were censored by rabies\n",
    "        phgy_df_allvar_fmriCensored = phgy_df_allvar.loc[rabies_censoring_df['False = Masked Frames'], :].reset_index(drop = True)\n",
    "        phgy_df_selectvar_fmriCensored = phgy_df_selectvar.loc[rabies_censoring_df['False = Masked Frames'], :].reset_index(drop = True)\n",
    "        \n",
    "        #drop rows in full_session_info that were censored by rabies\n",
    "        full_session_info_fmriCensored = full_session_info.loc[rabies_censoring_df['False = Masked Frames'], :].reset_index(drop = True)\n",
    "        \n",
    "        #create a boolean list of 'True' for each timepoint of the scan (this is the same format as rabies csvs)\n",
    "        phgy_censoring_list = [True] * original_num_timepoints\n",
    "        #Then, for certain sessions, censor the session (or part of it) by changing the True to False\n",
    "        #first, check if this particular subject is in the list of ones that need to be censored\n",
    "        list_censoring_duration_per_sub = list(censoring_duration_dict.keys())\n",
    "        if sub_ses_ID in list_censoring_duration_per_sub:\n",
    "            #if so, extract the censor start and end time\n",
    "            censor_starttime = censoring_duration_dict[sub_ses_ID][0]\n",
    "            censor_endtime = censoring_duration_dict[sub_ses_ID][1]\n",
    "            #modify the phgy censoring list for this subject so that those timepoints now read false\n",
    "            phgy_censoring_list[censor_starttime : censor_endtime] = [False] * (censor_endtime-censor_starttime)\n",
    "        phgy_censoring_df = pd.DataFrame(phgy_censoring_list)\n",
    "        \n",
    "        #there are still some remaining NaN rows, I want to mask out any row with these because it won't run the clustering\n",
    "        nan_censoring_df_tmp = phgy_df_selectvar.isna().any(axis = 1).reset_index(drop=True) \n",
    "        nan_censoring_df = (nan_censoring_df_tmp == False)\n",
    "        \n",
    "        #combine nan_censoring_df and phgy_censoring_df into one censoring_df\n",
    "        phgy_nan_censoring_df = (nan_censoring_df) & (phgy_censoring_df[0])\n",
    "        fmri_phgy_nan_censoring_df = rabies_censoring_df['False = Masked Frames'] & (nan_censoring_df) & (phgy_censoring_df[0])\n",
    "        \n",
    "        #now, because we were working with the original number of timepoints (because we determined censor times based on the phgyQC images), also drop those that were removed during fmri-based censoring\n",
    "        phgy_nan_censoring_df_final = phgy_nan_censoring_df.loc[rabies_censoring_df['False = Masked Frames']].reset_index(drop = True)\n",
    "\n",
    "        #finally, apply the phgy and nan censoring to the phgy data and session_info\n",
    "        phgy_df_selectvar_allCensored = phgy_df_selectvar_fmriCensored.loc[phgy_nan_censoring_df_final, :]\n",
    "        full_session_info_allCensored = full_session_info_fmriCensored.loc[phgy_nan_censoring_df_final, :]\n",
    "        \n",
    "        #################################### ZSCORE ON A PER SUBJECT BASIS ###################################\n",
    "        #the apply function will only work if the dataframe is not completely censored (ie not empty)\n",
    "        if phgy_df_selectvar_allCensored.shape[0] != 0:\n",
    "            phgy_df_selectvar_allCensored_zscored = phgy_df_selectvar_allCensored.apply(zscore)\n",
    "        else:\n",
    "            #if it is empty, no need to zscore\n",
    "            phgy_df_selectvar_allCensored_zscored = phgy_df_selectvar_allCensored\n",
    "        \n",
    "        #save in dict\n",
    "        phgy_dict_allvar[sub_ses_ID] = phgy_df_allvar_fmriCensored\n",
    "        phgy_dict_selectvar[sub_ses_ID] = phgy_df_selectvar_allCensored\n",
    "        phgy_dict_selectvar_precensor[sub_ses_ID] = phgy_df_selectvar\n",
    "        phgy_dict_selectvar_zscored[sub_ses_ID] = phgy_df_selectvar_allCensored_zscored\n",
    "        phgy_shape_postCensor_dict[sub_ses_ID] = phgy_df_selectvar_allCensored.shape[0]\n",
    "        phgy_nan_censoring_dict[sub_ses_ID] = phgy_nan_censoring_df_final\n",
    "        fmri_phgy_nan_censoring_dict[sub_ses_ID] = fmri_phgy_nan_censoring_df\n",
    "        session_info_dict[sub_ses_ID] = full_session_info_allCensored\n",
    "        \n",
    "        #sort the dict so it has same order as fmri dict\n",
    "        phgy_dict_selectvar_sorted = OrderedDict(sorted(phgy_dict_selectvar.items()))\n",
    "        phgy_dict_selectvar_precensor_sorted = OrderedDict(sorted(phgy_dict_selectvar_precensor.items()))\n",
    "        phgy_dict_selectvar_zscored_sorted = OrderedDict(sorted(phgy_dict_selectvar_zscored.items()))\n",
    "        phgy_shape_postCensor_dict_sorted = OrderedDict(sorted(phgy_shape_postCensor_dict.items()))\n",
    "        phgy_nan_censoring_dict_sorted = OrderedDict(sorted(phgy_nan_censoring_dict.items()))\n",
    "        fmri_phgy_nan_censoring_dict_sorted = OrderedDict(sorted(fmri_phgy_nan_censoring_dict.items()))\n",
    "        session_info_dict_sorted = OrderedDict(sorted(session_info_dict.items()))\n",
    "        \n",
    "        #print the progress\n",
    "        print(\"\\r\", 'loading file ' + str(i+1)  + ' out of ' + str(num_files_to_extract), end=\"\")\n",
    "    \n",
    "    #concatenate each file stored as an element of the dict\n",
    "    if output_dict_bool:\n",
    "        return phgy_dict_selectvar_precensor_sorted, phgy_dict_allvar, phgy_dict_selectvar_sorted, phgy_dict_selectvar_zscored_sorted, phgy_shape_postCensor_dict_sorted, phgy_nan_censoring_dict_sorted, fmri_phgy_nan_censoring_dict_sorted, session_info_dict_sorted\n",
    "    else:\n",
    "        phgy_arr_selectvar_zscored = pd.concat([phgy_dict_selectvar_zscored_sorted[x] for x in phgy_dict_selectvar_zscored_sorted], 0)\n",
    "        phgy_arr_selectvar_precensor = pd.concat([phgy_dict_selectvar_precensor_sorted[x] for x in phgy_dict_selectvar_precensor_sorted], 0)\n",
    "        phgy_arr_selectvar = pd.concat([phgy_dict_selectvar_sorted[x] for x in phgy_dict_selectvar_sorted], 0)\n",
    "        phgy_arr_allvar = pd.concat([phgy_dict_allvar[x] for x in phgy_dict_allvar], 0)\n",
    "        phgy_nan_censoring_arr = pd.concat([phgy_nan_censoring_dict_sorted[x] for x in phgy_nan_censoring_dict_sorted], 0)\n",
    "        fmri_phgy_nan_censoring_arr = pd.concat([fmri_phgy_nan_censoring_dict_sorted[x] for x in fmri_phgy_nan_censoring_dict_sorted], 0)\n",
    "        session_info_arr = pd.concat([session_info_dict_sorted[x] for x in session_info_dict_sorted], 0)\n",
    "        \n",
    "        return phgy_arr_selectvar_precensor, phgy_arr_allvar, phgy_arr_selectvar, phgy_arr_selectvar_zscored, phgy_shape_postCensor_dict_sorted, phgy_nan_censoring_arr, fmri_phgy_nan_censoring_arr, session_info_arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6314c",
   "metadata": {},
   "source": [
    "# Censor the physiology data and combine into one csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a076b1",
   "metadata": {},
   "source": [
    "Censor according to a) timepoints that don't pass the phgy QC, b) timepoints that are censored in the fmri timeseries\n",
    "due to motion, c) drop nan values that could not be estimated during phgy metric computation. Combine remaining phgy metrics into 1 csv per subject and session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188a816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually selected timepoints to censor from the physiology data - based on visual QC\n",
    "censor_duration_dict = {'sub-PHG004_ses-1': [0,1440], 'sub-PHG001_ses-2': [0,1440], 'sub-PHG005_ses-2': [0,1440],\n",
    "                           'sub-PHG004_ses-2': [1120,1440], 'sub-PHG013_ses-2': [1380,1440],\n",
    "                          'sub-PHG003_ses-3': [475,1440], 'sub-PHG007_ses-1': [0,1440], \n",
    "                           'sub-PHG008_ses-1': [0,450], 'sub-PHG016_ses-3': [1380,1440],\n",
    "                       'sub-PHG010_ses-3': [0,1440]}\n",
    "#sub-PHG010_ses-3 is also not there because the spo2 (rates) data is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a17cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loading file 46 out of 46"
     ]
    }
   ],
   "source": [
    "# perform censoring, save outputs into arrays\n",
    "phgy_arr_selectvar_precensor, phgy_arr_allvar, phgy_arr_selectvar, phgy_arr_selectvar_sub_zscored, phgy_dict_postCensor_shape, phgy_nan_censor, fmri_phgy_nan_censor, session_info_arr = extract_array_of_phgy_with_dict(resp_csvs, \n",
    "                                                                                                   pulseox_csvs, spo2_csvs, rabies_censoring_csv_path, rabies_FD_csv_path,\n",
    "                                                                                                   [0,46], False,1440,\n",
    "                                                                                                   censor_duration_dict, dataset_info_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save large files as pickle files so they can be easily loaded later without rerunning everything\n",
    "pickle.dump(phgy_dict_postCensor_shape, open(\"./pickle_files/phgy_dict_postCensor_shape_withEdgeCutoff\", \"wb\"))\n",
    "pickle.dump(phgy_nan_censor, open(\"./pickle_files/bool_series_phgy-nan_censoring_withEdgeCutoff\", \"wb\"))\n",
    "pickle.dump(fmri_phgy_nan_censor, open(\"./pickle_files/series_fmri_phgy_nan_censor\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f5992f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loading file 46 out of 46"
     ]
    }
   ],
   "source": [
    "#run censoring, save outputs as dict\n",
    "phgy_dict_selectvar_precensor, phgy_dict_allvar, phgy_dict_selectvar, phgy_dict_selectvar_sub_zscored, phgy_dict_postCensor_shape, phgy_nan_censor, fmri_phgy_nan_censor_dict, session_info_dict = extract_array_of_phgy_with_dict(resp_csvs, \n",
    "                                                                                                   pulseox_csvs, spo2_csvs, rabies_censoring_csv_path,rabies_FD_csv_path,\n",
    "                                                                                                   [0,46], True,1440,\n",
    "                                                                                                   censor_duration_dict, dataset_info_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save outputs as pickle files\n",
    "pickle.dump(phgy_dict_selectvar, open(\"./pickle_files/phgy_dict_selectvar\", \"wb\"))\n",
    "pickle.dump(phgy_dict_selectvar_precensor, open(\"./pickle_files/phgy_dict_selectvar_precensor\", \"wb\"))\n",
    "pickle.dump(fmri_phgy_nan_censor_dict, open(\"./pickle_files/dict_fmri_phgy_nan_censor\", \"wb\"))\n",
    "pickle.dump(phgy_nan_censor, open(\"./pickle_files/dict_phgy_nan_censor\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e9ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timepoints after removing timepoints also censored during fmri (should match total fmri timepoints), and number of phgy variables: (61561, 24)\n",
      "Number of timepoints after further removing timepoints that dont pass phgy QC and nan values, and final number of selected phgy variables: (52606, 7)\n"
     ]
    }
   ],
   "source": [
    "#check dimensions of outputs\n",
    "print('Number of timepoints after removing timepoints also censored during fmri (should match total fmri timepoints), and number of phgy variables: ' + str(phgy_arr_allvar.shape))\n",
    "print('Number of timepoints after further removing timepoints that dont pass phgy QC and nan values, and final number of selected phgy variables: ' + str(phgy_arr_selectvar.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f4f77",
   "metadata": {},
   "source": [
    "The numbers above checkout. 61561 is also the number of fmri timepoints (was 64055 before adding edge cutoff during fmri processing). 52606 is less than that (was 55200 before added edge cutoff in the fmri processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265a8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final csv\n",
    "phgy_arr_selectvar.to_csv(\"./phgy_metrics_final_csv/phgy_metrics_noZscore_selectvar_phgyfmriCensored.csv\")\n",
    "session_info_arr.to_csv(\"./phgy_metrics_final_csv/session_info_phgyfmriCensored.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
